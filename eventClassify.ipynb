{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from calamity import Calamity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] New event stan had been added\n",
      "[+] New event maria had been added\n",
      "[+] New event matthew had been added\n",
      "[+] New event katrina had been added\n",
      "[+] New event irma had been added\n",
      "[+] New event jeanne had been added\n",
      "[+] New event kashmir had been added\n",
      "[+] New event haiti had been added\n",
      "[+] New event sumatra had been added\n",
      "[+] New event sichuan had been added\n",
      "[+] New event attica had been added\n",
      "[+] New event thomas had been added\n",
      "[+] New event nevada had been added\n",
      "[+] New event carr had been added\n",
      "[+] New event mountcarmel had been added\n",
      "[+] New event virginiatech had been added\n",
      "[+] New event sandyhook had been added\n",
      "[+] New event aurora had been added\n",
      "[+] New event sanbernardino had been added\n",
      "[+] New event orlando had been added\n",
      "[+] New event lasvegas had been added\n",
      "[+] New event charliehebdo had been added\n",
      "[+] New event japan18 had been added\n",
      "[+] New event kerala had been added\n",
      "[+] New event gujarat had been added\n",
      "Object has been successfully loaded\n"
     ]
    }
   ],
   "source": [
    "archive = Calamity('disaster-archive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hurricanes', 'stan', 30),\n",
       " ('hurricanes', 'maria', 98),\n",
       " ('hurricanes', 'matthew', 100),\n",
       " ('hurricanes', 'katrina', 99),\n",
       " ('hurricanes', 'irma', 64),\n",
       " ('hurricanes', 'jeanne', 35),\n",
       " ('earthquakes', 'kashmir', 59),\n",
       " ('earthquakes', 'haiti', 100),\n",
       " ('earthquakes', 'sumatra', 86),\n",
       " ('earthquakes', 'sichuan', 100),\n",
       " ('wildfires', 'attica', 100),\n",
       " ('wildfires', 'thomas', 82),\n",
       " ('wildfires', 'nevada', 95),\n",
       " ('wildfires', 'carr', 100),\n",
       " ('wildfires', 'mountcarmel', 19),\n",
       " ('shootings', 'virginiatech', 100),\n",
       " ('shootings', 'sandyhook', 99),\n",
       " ('shootings', 'aurora', 100),\n",
       " ('shootings', 'sanbernardino', 97),\n",
       " ('shootings', 'orlando', 99),\n",
       " ('shootings', 'lasvegas', 100),\n",
       " ('shootings', 'charliehebdo', 100),\n",
       " ('floods', 'japan18', 101),\n",
       " ('floods', 'kerala', 100),\n",
       " ('floods', 'gujarat', 80)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.listTopics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEventMClassifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "#     'stan',\n",
    "    'maria',\n",
    "    'matthew',\n",
    "    'katrina',\n",
    "#     'irma',\n",
    "#     'jeanne',\n",
    "#     'kashmir',\n",
    "    'haiti',\n",
    "    'sumatra',\n",
    "    'sichuan',\n",
    "    'attica',\n",
    "    'thomas',\n",
    "    'nevada',\n",
    "    'carr',\n",
    "#     'mountcarmel',\n",
    "    'virginiatech',\n",
    "    'sandyhook',\n",
    "    'aurora',\n",
    "    'sanbernardino',\n",
    "    'orlando',\n",
    "    'lasvegas',\n",
    "    'charliehebdo',\n",
    "    'japan18',\n",
    "    'kerala',\n",
    "    'gujarat'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 100\n",
    "data = [archive.mergeEventArticles([x], CHUNK) for x in labels]\n",
    "\n",
    "train_data, test_data = [], []\n",
    "train_label, test_label = numpy.array([]), numpy.array([])\n",
    "\n",
    "TRAIN_SIZE = 50\n",
    "l = 0\n",
    "\n",
    "for cat in data:\n",
    "    for x in cat[:TRAIN_SIZE]:\n",
    "        train_data.append(x['text'])\n",
    "        train_label = numpy.append(train_label, l)\n",
    "    for x in cat[TRAIN_SIZE:]:\n",
    "        test_data.append(x['text'])\n",
    "        test_label = numpy.append(test_label, l)\n",
    "    l += 1\n",
    "\n",
    "test_data.extend(train_data)\n",
    "test_label = numpy.append(test_label, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    SGDClassifier(loss='hinge',\n",
    "                  penalty='elasticnet',\n",
    "                  alpha=1e-3,\n",
    "                  max_iter=1000,\n",
    "                  tol=None),\n",
    "    MultinomialNB(),\n",
    "    PassiveAggressiveClassifier(max_iter=200),\n",
    "    KNeighborsClassifier(n_neighbors=len(data)),\n",
    "    RandomForestClassifier(n_estimators=200,\n",
    "                           max_depth=3),\n",
    "    LogisticRegression(),\n",
    "    LinearSVC()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(text):\n",
    "    return (stemmer.stem(word) for word in analyzer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier 0.9772609819121447\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       1.00      0.98      0.99        98\n",
      "      matthew       0.95      0.93      0.94       100\n",
      "      katrina       0.99      1.00      0.99        99\n",
      "        haiti       0.93      0.99      0.96       100\n",
      "      sumatra       1.00      0.95      0.98        86\n",
      "      sichuan       0.99      1.00      1.00       100\n",
      "       attica       0.99      0.96      0.97       100\n",
      "       thomas       0.97      0.93      0.95        82\n",
      "       nevada       0.94      0.97      0.95        95\n",
      "         carr       0.93      0.98      0.96       100\n",
      " virginiatech       0.94      0.99      0.97       100\n",
      "    sandyhook       0.98      0.99      0.98        99\n",
      "       aurora       0.99      0.99      0.99       100\n",
      "sanbernardino       0.99      0.98      0.98        97\n",
      "      orlando       1.00      0.99      0.99        99\n",
      "     lasvegas       0.99      0.98      0.98       100\n",
      " charliehebdo       1.00      0.98      0.99       100\n",
      "      japan18       1.00      0.96      0.98       100\n",
      "       kerala       0.99      1.00      1.00       100\n",
      "      gujarat       0.99      0.99      0.99        80\n",
      "\n",
      "  avg / total       0.98      0.98      0.98      1935\n",
      "\n",
      "[[ 96   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  93   0   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  99   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0  82   0   0   0   1   0   2   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  96   0   1   2   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  76   2   3   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   0   0   0  92   1   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1  98   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  99   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  98   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0  95   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1  98   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  98   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0  98   0\n",
      "    0   0]\n",
      " [  0   2   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0  96\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  100   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1  79]]\n",
      "MultinomialNB 0.9607235142118863\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       0.94      0.99      0.97        98\n",
      "      matthew       1.00      0.78      0.88       100\n",
      "      katrina       0.91      0.99      0.95        99\n",
      "        haiti       0.86      0.98      0.92       100\n",
      "      sumatra       0.98      0.93      0.95        86\n",
      "      sichuan       0.99      0.97      0.98       100\n",
      "       attica       1.00      0.91      0.95       100\n",
      "       thomas       0.93      0.95      0.94        82\n",
      "       nevada       0.98      0.94      0.96        95\n",
      "         carr       0.91      0.97      0.94       100\n",
      " virginiatech       0.88      1.00      0.93       100\n",
      "    sandyhook       0.97      0.97      0.97        99\n",
      "       aurora       0.99      0.95      0.97       100\n",
      "sanbernardino       0.99      0.99      0.99        97\n",
      "      orlando       1.00      0.99      0.99        99\n",
      "     lasvegas       1.00      0.99      0.99       100\n",
      " charliehebdo       0.99      0.98      0.98       100\n",
      "      japan18       0.98      0.96      0.97       100\n",
      "       kerala       0.99      1.00      1.00       100\n",
      "      gujarat       1.00      0.97      0.99        80\n",
      "\n",
      "  avg / total       0.96      0.96      0.96      1935\n",
      "\n",
      "[[ 97   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3  78   6  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  98   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  98   0   0   0   0   0   1   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   2   0  80   1   0   0   0   0   3   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   2  97   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   1   0   0  91   2   0   3   1   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  78   1   3   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   0   0   0   0   0   0   0  89   3   1   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   2   1  97   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 100   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3  96   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   3  95   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  96   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  98   0   1   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0  99   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0  98   0\n",
      "    0   0]\n",
      " [  2   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0  96\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  100   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    1  78]]\n",
      "PassiveAggressiveClassifier 0.9803617571059432\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       1.00      0.99      0.99        98\n",
      "      matthew       0.99      0.93      0.96       100\n",
      "      katrina       0.97      1.00      0.99        99\n",
      "        haiti       0.97      0.98      0.98       100\n",
      "      sumatra       1.00      0.95      0.98        86\n",
      "      sichuan       0.98      1.00      0.99       100\n",
      "       attica       0.98      0.98      0.98       100\n",
      "       thomas       0.96      0.95      0.96        82\n",
      "       nevada       0.90      0.98      0.94        95\n",
      "         carr       0.97      0.97      0.97       100\n",
      " virginiatech       0.98      0.99      0.99       100\n",
      "    sandyhook       0.97      1.00      0.99        99\n",
      "       aurora       0.99      0.99      0.99       100\n",
      "sanbernardino       0.99      0.98      0.98        97\n",
      "      orlando       1.00      0.99      0.99        99\n",
      "     lasvegas       1.00      0.98      0.99       100\n",
      " charliehebdo       1.00      0.98      0.99       100\n",
      "      japan18       0.97      0.97      0.97       100\n",
      "       kerala       1.00      1.00      1.00       100\n",
      "      gujarat       0.99      0.99      0.99        80\n",
      "\n",
      "  avg / total       0.98      0.98      0.98      1935\n",
      "\n",
      "[[ 97   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0  93   0   3   0   0   0   0   3   0   0   1   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1  98   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0  82   1   0   0   0   0   2   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  98   0   1   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  78   1   2   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   1   0  93   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   2   1  97   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  99   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  99   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0  95   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1  98   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  98   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   0  98   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   2   0   0   0   0   0   0   0   0  97\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  100   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0  79]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.9235142118863049\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       0.97      0.95      0.96        98\n",
      "      matthew       0.74      0.88      0.80       100\n",
      "      katrina       0.91      0.93      0.92        99\n",
      "        haiti       0.93      0.92      0.92       100\n",
      "      sumatra       0.88      0.93      0.90        86\n",
      "      sichuan       0.92      0.98      0.95       100\n",
      "       attica       1.00      0.78      0.88       100\n",
      "       thomas       0.99      0.85      0.92        82\n",
      "       nevada       0.95      0.79      0.86        95\n",
      "         carr       0.77      0.97      0.86       100\n",
      " virginiatech       0.93      0.96      0.95       100\n",
      "    sandyhook       0.84      0.93      0.88        99\n",
      "       aurora       0.99      0.93      0.96       100\n",
      "sanbernardino       0.98      0.96      0.97        97\n",
      "      orlando       1.00      0.96      0.98        99\n",
      "     lasvegas       0.95      0.98      0.97       100\n",
      " charliehebdo       0.98      0.98      0.98       100\n",
      "      japan18       0.96      0.93      0.94       100\n",
      "       kerala       0.93      0.98      0.96       100\n",
      "      gujarat       1.00      0.85      0.92        80\n",
      "\n",
      "  avg / total       0.93      0.92      0.92      1935\n",
      "\n",
      "[[93  2  1  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 3 88  1  6  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0]\n",
      " [ 0  4 92  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  0 92  1  2  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  3  0 80  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2 98  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  8  0  0  3  2 78  1  2  5  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  1  0  0 70  0  8  0  1  0  0  0  0  1  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0 75 16  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2 97  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 96  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  1  0  0  0  0  3 92  0  0  0  1  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  3  2 93  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0 93  0  1  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  2 95  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0 98  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  1  0  0  0  0 98  0  0  0]\n",
      " [ 0  4  0  0  0  1  0  0  0  0  0  1  0  0  0  0  0 93  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 98  0]\n",
      " [ 0  4  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  1  5 68]]\n",
      "RandomForestClassifier 0.9612403100775194\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       0.99      0.94      0.96        98\n",
      "      matthew       0.78      0.87      0.82       100\n",
      "      katrina       0.93      1.00      0.96        99\n",
      "        haiti       0.88      0.96      0.92       100\n",
      "      sumatra       0.98      0.93      0.95        86\n",
      "      sichuan       0.97      0.98      0.98       100\n",
      "       attica       0.99      0.98      0.98       100\n",
      "       thomas       0.95      0.91      0.93        82\n",
      "       nevada       0.95      0.93      0.94        95\n",
      "         carr       0.98      0.96      0.97       100\n",
      " virginiatech       0.97      0.98      0.98       100\n",
      "    sandyhook       0.99      0.98      0.98        99\n",
      "       aurora       0.98      0.95      0.96       100\n",
      "sanbernardino       1.00      0.97      0.98        97\n",
      "      orlando       0.99      0.99      0.99        99\n",
      "     lasvegas       0.98      0.98      0.98       100\n",
      " charliehebdo       0.99      0.98      0.98       100\n",
      "      japan18       0.99      0.95      0.97       100\n",
      "       kerala       0.99      0.98      0.98       100\n",
      "      gujarat       1.00      1.00      1.00        80\n",
      "\n",
      "  avg / total       0.96      0.96      0.96      1935\n",
      "\n",
      "[[92  5  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 87  2 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 99  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 96  1  2  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  1  1 80  0  1  0  0  0  0  0  0  0  0  0  1  1  0  0]\n",
      " [ 0  0  0  1  1 98  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0 98  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0 75  3  2  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  2  1  0  0  0  0  3 88  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  1  1 96  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0 98  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1 97  1  0  0  0  0  0  0  0]\n",
      " [ 0  3  1  0  0  0  0  0  0  0  1  0 95  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0 94  0  0  0  0  1  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  1 98  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0  0  0]\n",
      " [ 0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 95  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 98  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 80]]\n",
      "LogisticRegression 0.9736434108527132\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       1.00      0.98      0.99        98\n",
      "      matthew       0.88      0.92      0.90       100\n",
      "      katrina       0.96      0.99      0.98        99\n",
      "        haiti       0.92      0.98      0.95       100\n",
      "      sumatra       1.00      0.93      0.96        86\n",
      "      sichuan       1.00      0.99      0.99       100\n",
      "       attica       0.98      0.95      0.96       100\n",
      "       thomas       0.96      0.95      0.96        82\n",
      "       nevada       0.97      0.98      0.97        95\n",
      "         carr       0.95      0.96      0.96       100\n",
      " virginiatech       0.99      0.98      0.98       100\n",
      "    sandyhook       0.96      1.00      0.98        99\n",
      "       aurora       0.96      0.98      0.97       100\n",
      "sanbernardino       1.00      0.98      0.99        97\n",
      "      orlando       1.00      0.99      0.99        99\n",
      "     lasvegas       1.00      0.97      0.98       100\n",
      " charliehebdo       1.00      0.98      0.99       100\n",
      "      japan18       0.97      0.97      0.97       100\n",
      "       kerala       1.00      1.00      1.00       100\n",
      "      gujarat       0.98      0.99      0.98        80\n",
      "\n",
      "  avg / total       0.97      0.97      0.97      1935\n",
      "\n",
      "[[ 96   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0  92   0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1]\n",
      " [  0   1   0  98   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   3   0  80   0   1   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0  99   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0  95   0   0   3   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  78   1   2   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   1   0  93   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   2   2  96   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0  98   1   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  99   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   2  98   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1  95   0   0   0   0\n",
      "    0   1]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0  98   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1   2   0   0  97   0   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0  98   0\n",
      "    0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  97\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  100   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0  79]]\n",
      "LinearSVC 0.9808785529715762\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        maria       1.00      0.99      0.99        98\n",
      "      matthew       0.96      0.96      0.96       100\n",
      "      katrina       0.99      1.00      0.99        99\n",
      "        haiti       0.96      0.99      0.98       100\n",
      "      sumatra       1.00      0.95      0.98        86\n",
      "      sichuan       1.00      1.00      1.00       100\n",
      "       attica       0.99      0.97      0.98       100\n",
      "       thomas       0.92      0.96      0.94        82\n",
      "       nevada       0.90      0.97      0.93        95\n",
      "         carr       0.96      0.97      0.97       100\n",
      " virginiatech       1.00      0.99      0.99       100\n",
      "    sandyhook       0.98      0.99      0.98        99\n",
      "       aurora       0.99      0.99      0.99       100\n",
      "sanbernardino       0.99      0.98      0.98        97\n",
      "      orlando       1.00      0.99      0.99        99\n",
      "     lasvegas       0.99      0.98      0.98       100\n",
      " charliehebdo       1.00      0.98      0.99       100\n",
      "      japan18       1.00      0.96      0.98       100\n",
      "       kerala       1.00      1.00      1.00       100\n",
      "      gujarat       0.99      0.99      0.99        80\n",
      "\n",
      "  avg / total       0.98      0.98      0.98      1935\n",
      "\n",
      "[[ 97   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  96   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0  99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  99   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0  82   0   0   0   3   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  97   1   1   1   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0  79   1   2   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   0   1   0  92   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   2   1  97   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  99   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  98   0   0   0   1   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   1  99   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   0   0   0  95   0   0   0   0\n",
      "    0   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   1  98   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   1   0   0   0  98   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   1   0   0   0   0   0   0   0  98   0\n",
      "    0   0]\n",
      " [  0   2   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0  96\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  100   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0  79]]\n"
     ]
    }
   ],
   "source": [
    "for c in classifiers:\n",
    "    clf = Pipeline([('vect', CountVectorizer(analyzer=stemmed_words,\n",
    "                                             stop_words='english')),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', c),\n",
    "    ])\n",
    "    clf.fit(train_data, train_label)\n",
    "    pred_label = clf.predict(test_data)\n",
    "    print(type(c).__name__, accuracy_score(test_label, pred_label))\n",
    "    print(classification_report(test_label, pred_label, target_names = labels))\n",
    "    print(confusion_matrix(test_label, pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1EventvAll\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier 0.9797979797979798\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.99      0.97      0.98        98\n",
      "     others       0.97      0.99      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       198\n",
      "\n",
      "[[95  3]\n",
      " [ 1 99]]\n",
      "MultinomialNB 0.8484848484848485\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.77      1.00      0.87        98\n",
      "     others       1.00      0.70      0.82       100\n",
      "\n",
      "avg / total       0.88      0.85      0.85       198\n",
      "\n",
      "[[98  0]\n",
      " [30 70]]\n",
      "PassiveAggressiveClassifier 0.9747474747474747\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.97      0.98      0.97        98\n",
      "     others       0.98      0.97      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       198\n",
      "\n",
      "[[96  2]\n",
      " [ 3 97]]\n",
      "KNeighborsClassifier 0.5050505050505051\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.50      1.00      0.67        98\n",
      "     others       1.00      0.02      0.04       100\n",
      "\n",
      "avg / total       0.75      0.51      0.35       198\n",
      "\n",
      "[[98  0]\n",
      " [98  2]]\n",
      "RandomForestClassifier 0.9343434343434344\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.96      0.91      0.93        98\n",
      "     others       0.91      0.96      0.94       100\n",
      "\n",
      "avg / total       0.94      0.93      0.93       198\n",
      "\n",
      "[[89  9]\n",
      " [ 4 96]]\n",
      "LogisticRegression 0.9595959595959596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.96      0.96      0.96        98\n",
      "     others       0.96      0.96      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       198\n",
      "\n",
      "[[94  4]\n",
      " [ 4 96]]\n",
      "LinearSVC 0.9747474747474747\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      maria       0.98      0.97      0.97        98\n",
      "     others       0.97      0.98      0.98       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       198\n",
      "\n",
      "[[95  3]\n",
      " [ 2 98]]\n",
      "SGDClassifier 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.97      0.97      0.97       100\n",
      "     others       0.97      0.97      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[97  3]\n",
      " [ 3 97]]\n",
      "MultinomialNB 0.94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.90      0.99      0.94       100\n",
      "     others       0.99      0.89      0.94       100\n",
      "\n",
      "avg / total       0.94      0.94      0.94       200\n",
      "\n",
      "[[99  1]\n",
      " [11 89]]\n",
      "PassiveAggressiveClassifier 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.98      0.94      0.96       100\n",
      "     others       0.94      0.98      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       200\n",
      "\n",
      "[[94  6]\n",
      " [ 2 98]]\n",
      "KNeighborsClassifier 0.565\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.53      1.00      0.70       100\n",
      "     others       1.00      0.13      0.23       100\n",
      "\n",
      "avg / total       0.77      0.56      0.46       200\n",
      "\n",
      "[[100   0]\n",
      " [ 87  13]]\n",
      "RandomForestClassifier 0.95\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.99      0.91      0.95       100\n",
      "     others       0.92      0.99      0.95       100\n",
      "\n",
      "avg / total       0.95      0.95      0.95       200\n",
      "\n",
      "[[91  9]\n",
      " [ 1 99]]\n",
      "LogisticRegression 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.98      0.94      0.96       100\n",
      "     others       0.94      0.98      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       200\n",
      "\n",
      "[[94  6]\n",
      " [ 2 98]]\n",
      "LinearSVC 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    matthew       0.98      0.94      0.96       100\n",
      "     others       0.94      0.98      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       200\n",
      "\n",
      "[[94  6]\n",
      " [ 2 98]]\n",
      "SGDClassifier 0.9849246231155779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.98      0.99      0.98        99\n",
      "     others       0.99      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       199\n",
      "\n",
      "[[98  1]\n",
      " [ 2 98]]\n",
      "MultinomialNB 0.8190954773869347\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.73      1.00      0.85        99\n",
      "     others       1.00      0.64      0.78       100\n",
      "\n",
      "avg / total       0.87      0.82      0.81       199\n",
      "\n",
      "[[99  0]\n",
      " [36 64]]\n",
      "PassiveAggressiveClassifier 0.9849246231155779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.98      0.99      0.98        99\n",
      "     others       0.99      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       199\n",
      "\n",
      "[[98  1]\n",
      " [ 2 98]]\n",
      "KNeighborsClassifier 0.5728643216080402\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.54      1.00      0.70        99\n",
      "     others       1.00      0.15      0.26       100\n",
      "\n",
      "avg / total       0.77      0.57      0.48       199\n",
      "\n",
      "[[99  0]\n",
      " [85 15]]\n",
      "RandomForestClassifier 0.9447236180904522\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.92      0.97      0.95        99\n",
      "     others       0.97      0.92      0.94       100\n",
      "\n",
      "avg / total       0.95      0.94      0.94       199\n",
      "\n",
      "[[96  3]\n",
      " [ 8 92]]\n",
      "LogisticRegression 0.9698492462311558\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.94      1.00      0.97        99\n",
      "     others       1.00      0.94      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       199\n",
      "\n",
      "[[99  0]\n",
      " [ 6 94]]\n",
      "LinearSVC 0.9849246231155779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    katrina       0.98      0.99      0.98        99\n",
      "     others       0.99      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       199\n",
      "\n",
      "[[98  1]\n",
      " [ 2 98]]\n",
      "SGDClassifier 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.97      1.00      0.99       100\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  3  97]]\n",
      "MultinomialNB 0.87\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.79      1.00      0.88       100\n",
      "     others       1.00      0.74      0.85       100\n",
      "\n",
      "avg / total       0.90      0.87      0.87       200\n",
      "\n",
      "[[100   0]\n",
      " [ 26  74]]\n",
      "PassiveAggressiveClassifier 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.95      0.99      0.97       100\n",
      "     others       0.99      0.95      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[99  1]\n",
      " [ 5 95]]\n",
      "KNeighborsClassifier 0.605\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.56      1.00      0.72       100\n",
      "     others       1.00      0.21      0.35       100\n",
      "\n",
      "avg / total       0.78      0.60      0.53       200\n",
      "\n",
      "[[100   0]\n",
      " [ 79  21]]\n",
      "RandomForestClassifier 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.93      0.93      0.93       100\n",
      "     others       0.93      0.93      0.93       100\n",
      "\n",
      "avg / total       0.93      0.93      0.93       200\n",
      "\n",
      "[[93  7]\n",
      " [ 7 93]]\n",
      "LogisticRegression 0.94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.90      0.99      0.94       100\n",
      "     others       0.99      0.89      0.94       100\n",
      "\n",
      "avg / total       0.94      0.94      0.94       200\n",
      "\n",
      "[[99  1]\n",
      " [11 89]]\n",
      "LinearSVC 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      haiti       0.94      1.00      0.97       100\n",
      "     others       1.00      0.94      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[100   0]\n",
      " [  6  94]]\n",
      "SGDClassifier 0.989247311827957\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       1.00      0.98      0.99        86\n",
      "     others       0.98      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       186\n",
      "\n",
      "[[ 84   2]\n",
      " [  0 100]]\n",
      "MultinomialNB 0.8602150537634409\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       0.77      1.00      0.87        86\n",
      "     others       1.00      0.74      0.85       100\n",
      "\n",
      "avg / total       0.89      0.86      0.86       186\n",
      "\n",
      "[[86  0]\n",
      " [26 74]]\n",
      "PassiveAggressiveClassifier 0.978494623655914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       0.98      0.98      0.98        86\n",
      "     others       0.98      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       186\n",
      "\n",
      "[[84  2]\n",
      " [ 2 98]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.478494623655914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       0.47      1.00      0.64        86\n",
      "     others       1.00      0.03      0.06       100\n",
      "\n",
      "avg / total       0.75      0.48      0.33       186\n",
      "\n",
      "[[86  0]\n",
      " [97  3]]\n",
      "RandomForestClassifier 0.9516129032258065\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       0.98      0.92      0.95        86\n",
      "     others       0.93      0.98      0.96       100\n",
      "\n",
      "avg / total       0.95      0.95      0.95       186\n",
      "\n",
      "[[79  7]\n",
      " [ 2 98]]\n",
      "LogisticRegression 0.967741935483871\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       0.95      0.98      0.97        86\n",
      "     others       0.98      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       186\n",
      "\n",
      "[[84  2]\n",
      " [ 4 96]]\n",
      "LinearSVC 0.978494623655914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sumatra       0.98      0.98      0.98        86\n",
      "     others       0.98      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       186\n",
      "\n",
      "[[84  2]\n",
      " [ 2 98]]\n",
      "SGDClassifier 0.995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       0.99      1.00      1.00       100\n",
      "     others       1.00      0.99      0.99       100\n",
      "\n",
      "avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[100   0]\n",
      " [  1  99]]\n",
      "MultinomialNB 0.885\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       0.81      1.00      0.90       100\n",
      "     others       1.00      0.77      0.87       100\n",
      "\n",
      "avg / total       0.91      0.89      0.88       200\n",
      "\n",
      "[[100   0]\n",
      " [ 23  77]]\n",
      "PassiveAggressiveClassifier 0.995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       0.99      1.00      1.00       100\n",
      "     others       1.00      0.99      0.99       100\n",
      "\n",
      "avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[100   0]\n",
      " [  1  99]]\n",
      "KNeighborsClassifier 0.505\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       0.50      1.00      0.67       100\n",
      "     others       1.00      0.01      0.02       100\n",
      "\n",
      "avg / total       0.75      0.51      0.34       200\n",
      "\n",
      "[[100   0]\n",
      " [ 99   1]]\n",
      "RandomForestClassifier 0.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       0.99      0.99      0.99       100\n",
      "     others       0.99      0.99      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "[[99  1]\n",
      " [ 1 99]]\n",
      "LogisticRegression 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       0.94      0.99      0.97       100\n",
      "     others       0.99      0.94      0.96       100\n",
      "\n",
      "avg / total       0.97      0.96      0.96       200\n",
      "\n",
      "[[99  1]\n",
      " [ 6 94]]\n",
      "LinearSVC 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    sichuan       1.00      1.00      1.00       100\n",
      "     others       1.00      1.00      1.00       100\n",
      "\n",
      "avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "[[100   0]\n",
      " [  0 100]]\n",
      "SGDClassifier 0.975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.99      0.96      0.97       100\n",
      "     others       0.96      0.99      0.98       100\n",
      "\n",
      "avg / total       0.98      0.97      0.97       200\n",
      "\n",
      "[[96  4]\n",
      " [ 1 99]]\n",
      "MultinomialNB 0.975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.99      0.96      0.97       100\n",
      "     others       0.96      0.99      0.98       100\n",
      "\n",
      "avg / total       0.98      0.97      0.97       200\n",
      "\n",
      "[[96  4]\n",
      " [ 1 99]]\n",
      "PassiveAggressiveClassifier 0.975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.99      0.96      0.97       100\n",
      "     others       0.96      0.99      0.98       100\n",
      "\n",
      "avg / total       0.98      0.97      0.97       200\n",
      "\n",
      "[[96  4]\n",
      " [ 1 99]]\n",
      "KNeighborsClassifier 0.885\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.89      0.88      0.88       100\n",
      "     others       0.88      0.89      0.89       100\n",
      "\n",
      "avg / total       0.89      0.89      0.88       200\n",
      "\n",
      "[[88 12]\n",
      " [11 89]]\n",
      "RandomForestClassifier 0.92\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.87      0.99      0.93       100\n",
      "     others       0.99      0.85      0.91       100\n",
      "\n",
      "avg / total       0.93      0.92      0.92       200\n",
      "\n",
      "[[99  1]\n",
      " [15 85]]\n",
      "LogisticRegression 0.975\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.99      0.96      0.97       100\n",
      "     others       0.96      0.99      0.98       100\n",
      "\n",
      "avg / total       0.98      0.97      0.97       200\n",
      "\n",
      "[[96  4]\n",
      " [ 1 99]]\n",
      "LinearSVC 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     attica       0.99      0.97      0.98       100\n",
      "     others       0.97      0.99      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[97  3]\n",
      " [ 1 99]]\n",
      "SGDClassifier 0.978021978021978\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.96      0.99      0.98        82\n",
      "     others       0.99      0.97      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       182\n",
      "\n",
      "[[81  1]\n",
      " [ 3 97]]\n",
      "MultinomialNB 0.9230769230769231\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.86      0.99      0.92        82\n",
      "     others       0.99      0.87      0.93       100\n",
      "\n",
      "avg / total       0.93      0.92      0.92       182\n",
      "\n",
      "[[81  1]\n",
      " [13 87]]\n",
      "PassiveAggressiveClassifier 0.9725274725274725\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.95      0.99      0.97        82\n",
      "     others       0.99      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       182\n",
      "\n",
      "[[81  1]\n",
      " [ 4 96]]\n",
      "KNeighborsClassifier 0.7197802197802198\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.62      1.00      0.76        82\n",
      "     others       1.00      0.49      0.66       100\n",
      "\n",
      "avg / total       0.83      0.72      0.71       182\n",
      "\n",
      "[[82  0]\n",
      " [51 49]]\n",
      "RandomForestClassifier 0.9230769230769231\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.91      0.91      0.91        82\n",
      "     others       0.93      0.93      0.93       100\n",
      "\n",
      "avg / total       0.92      0.92      0.92       182\n",
      "\n",
      "[[75  7]\n",
      " [ 7 93]]\n",
      "LogisticRegression 0.9340659340659341\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.90      0.96      0.93        82\n",
      "     others       0.97      0.91      0.94       100\n",
      "\n",
      "avg / total       0.94      0.93      0.93       182\n",
      "\n",
      "[[79  3]\n",
      " [ 9 91]]\n",
      "LinearSVC 0.967032967032967\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     thomas       0.95      0.98      0.96        82\n",
      "     others       0.98      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       182\n",
      "\n",
      "[[80  2]\n",
      " [ 4 96]]\n",
      "SGDClassifier 0.9692307692307692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.96      0.98      0.97        95\n",
      "     others       0.98      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       195\n",
      "\n",
      "[[93  2]\n",
      " [ 4 96]]\n",
      "MultinomialNB 0.9435897435897436\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.90      0.99      0.94        95\n",
      "     others       0.99      0.90      0.94       100\n",
      "\n",
      "avg / total       0.95      0.94      0.94       195\n",
      "\n",
      "[[94  1]\n",
      " [10 90]]\n",
      "PassiveAggressiveClassifier 0.9538461538461539\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.95      0.96      0.95        95\n",
      "     others       0.96      0.95      0.95       100\n",
      "\n",
      "avg / total       0.95      0.95      0.95       195\n",
      "\n",
      "[[91  4]\n",
      " [ 5 95]]\n",
      "KNeighborsClassifier 0.882051282051282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.83      0.96      0.89        95\n",
      "     others       0.95      0.81      0.88       100\n",
      "\n",
      "avg / total       0.89      0.88      0.88       195\n",
      "\n",
      "[[91  4]\n",
      " [19 81]]\n",
      "RandomForestClassifier 0.9641025641025641\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.94      0.99      0.96        95\n",
      "     others       0.99      0.94      0.96       100\n",
      "\n",
      "avg / total       0.97      0.96      0.96       195\n",
      "\n",
      "[[94  1]\n",
      " [ 6 94]]\n",
      "LogisticRegression 0.9435897435897436\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.93      0.96      0.94        95\n",
      "     others       0.96      0.93      0.94       100\n",
      "\n",
      "avg / total       0.94      0.94      0.94       195\n",
      "\n",
      "[[91  4]\n",
      " [ 7 93]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 0.9692307692307692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     nevada       0.96      0.98      0.97        95\n",
      "     others       0.98      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       195\n",
      "\n",
      "[[93  2]\n",
      " [ 4 96]]\n",
      "SGDClassifier 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.96      0.97      0.97       100\n",
      "     others       0.97      0.96      0.96       100\n",
      "\n",
      "avg / total       0.97      0.96      0.96       200\n",
      "\n",
      "[[97  3]\n",
      " [ 4 96]]\n",
      "MultinomialNB 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.88      1.00      0.93       100\n",
      "     others       1.00      0.86      0.92       100\n",
      "\n",
      "avg / total       0.94      0.93      0.93       200\n",
      "\n",
      "[[100   0]\n",
      " [ 14  86]]\n",
      "PassiveAggressiveClassifier 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.95      0.98      0.97       100\n",
      "     others       0.98      0.95      0.96       100\n",
      "\n",
      "avg / total       0.97      0.96      0.96       200\n",
      "\n",
      "[[98  2]\n",
      " [ 5 95]]\n",
      "KNeighborsClassifier 0.54\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.52      1.00      0.68       100\n",
      "     others       1.00      0.08      0.15       100\n",
      "\n",
      "avg / total       0.76      0.54      0.42       200\n",
      "\n",
      "[[100   0]\n",
      " [ 92   8]]\n",
      "RandomForestClassifier 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.94      0.92      0.93       100\n",
      "     others       0.92      0.94      0.93       100\n",
      "\n",
      "avg / total       0.93      0.93      0.93       200\n",
      "\n",
      "[[92  8]\n",
      " [ 6 94]]\n",
      "LogisticRegression 0.94\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.92      0.96      0.94       100\n",
      "     others       0.96      0.92      0.94       100\n",
      "\n",
      "avg / total       0.94      0.94      0.94       200\n",
      "\n",
      "[[96  4]\n",
      " [ 8 92]]\n",
      "LinearSVC 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       carr       0.94      0.99      0.97       100\n",
      "     others       0.99      0.94      0.96       100\n",
      "\n",
      "avg / total       0.97      0.96      0.96       200\n",
      "\n",
      "[[99  1]\n",
      " [ 6 94]]\n",
      "SGDClassifier 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.99      0.99      0.99       100\n",
      "      others       0.99      0.99      0.99       100\n",
      "\n",
      " avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "[[99  1]\n",
      " [ 1 99]]\n",
      "MultinomialNB 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.80      1.00      0.89       100\n",
      "      others       1.00      0.75      0.86       100\n",
      "\n",
      " avg / total       0.90      0.88      0.87       200\n",
      "\n",
      "[[100   0]\n",
      " [ 25  75]]\n",
      "PassiveAggressiveClassifier 0.995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.99      1.00      1.00       100\n",
      "      others       1.00      0.99      0.99       100\n",
      "\n",
      " avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[100   0]\n",
      " [  1  99]]\n",
      "KNeighborsClassifier 0.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.52      1.00      0.68       100\n",
      "      others       1.00      0.07      0.13       100\n",
      "\n",
      " avg / total       0.76      0.54      0.41       200\n",
      "\n",
      "[[100   0]\n",
      " [ 93   7]]\n",
      "RandomForestClassifier 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.98      0.96      0.97       100\n",
      "      others       0.96      0.98      0.97       100\n",
      "\n",
      " avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[96  4]\n",
      " [ 2 98]]\n",
      "LogisticRegression 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.96      1.00      0.98       100\n",
      "      others       1.00      0.96      0.98       100\n",
      "\n",
      " avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  4  96]]\n",
      "LinearSVC 0.985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "virginiatech       0.97      1.00      0.99       100\n",
      "      others       1.00      0.97      0.98       100\n",
      "\n",
      " avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  3  97]]\n",
      "SGDClassifier 0.9899497487437185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       1.00      0.98      0.99        99\n",
      "     others       0.98      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       199\n",
      "\n",
      "[[ 97   2]\n",
      " [  0 100]]\n",
      "MultinomialNB 0.914572864321608\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       0.85      1.00      0.92        99\n",
      "     others       1.00      0.83      0.91       100\n",
      "\n",
      "avg / total       0.93      0.91      0.91       199\n",
      "\n",
      "[[99  0]\n",
      " [17 83]]\n",
      "PassiveAggressiveClassifier 0.9899497487437185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       0.98      1.00      0.99        99\n",
      "     others       1.00      0.98      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       199\n",
      "\n",
      "[[99  0]\n",
      " [ 2 98]]\n",
      "KNeighborsClassifier 0.6482412060301508\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       0.59      1.00      0.74        99\n",
      "     others       1.00      0.30      0.46       100\n",
      "\n",
      "avg / total       0.79      0.65      0.60       199\n",
      "\n",
      "[[99  0]\n",
      " [70 30]]\n",
      "RandomForestClassifier 0.9899497487437185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       1.00      0.98      0.99        99\n",
      "     others       0.98      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       199\n",
      "\n",
      "[[ 97   2]\n",
      " [  0 100]]\n",
      "LogisticRegression 0.9748743718592965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       0.98      0.97      0.97        99\n",
      "     others       0.97      0.98      0.98       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       199\n",
      "\n",
      "[[96  3]\n",
      " [ 2 98]]\n",
      "LinearSVC 0.9849246231155779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  sandyhook       1.00      0.97      0.98        99\n",
      "     others       0.97      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       199\n",
      "\n",
      "[[ 96   3]\n",
      " [  0 100]]\n",
      "SGDClassifier 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.99      0.98      0.98       100\n",
      "     others       0.98      0.99      0.99       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[98  2]\n",
      " [ 1 99]]\n",
      "MultinomialNB 0.89\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.82      1.00      0.90       100\n",
      "     others       1.00      0.78      0.88       100\n",
      "\n",
      "avg / total       0.91      0.89      0.89       200\n",
      "\n",
      "[[100   0]\n",
      " [ 22  78]]\n",
      "PassiveAggressiveClassifier 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.97      1.00      0.99       100\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  3  97]]\n",
      "KNeighborsClassifier 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.63      1.00      0.78       100\n",
      "     others       1.00      0.42      0.59       100\n",
      "\n",
      "avg / total       0.82      0.71      0.68       200\n",
      "\n",
      "[[100   0]\n",
      " [ 58  42]]\n",
      "RandomForestClassifier 0.965\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.99      0.94      0.96       100\n",
      "     others       0.94      0.99      0.97       100\n",
      "\n",
      "avg / total       0.97      0.96      0.96       200\n",
      "\n",
      "[[94  6]\n",
      " [ 1 99]]\n",
      "LogisticRegression 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.96      0.98      0.97       100\n",
      "     others       0.98      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[98  2]\n",
      " [ 4 96]]\n",
      "LinearSVC 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     aurora       0.98      0.98      0.98       100\n",
      "     others       0.98      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[98  2]\n",
      " [ 2 98]]\n",
      "SGDClassifier 0.9847715736040609\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       1.00      0.97      0.98        97\n",
      "       others       0.97      1.00      0.99       100\n",
      "\n",
      "  avg / total       0.99      0.98      0.98       197\n",
      "\n",
      "[[ 94   3]\n",
      " [  0 100]]\n",
      "MultinomialNB 0.868020304568528\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       0.79      0.99      0.88        97\n",
      "       others       0.99      0.75      0.85       100\n",
      "\n",
      "  avg / total       0.89      0.87      0.87       197\n",
      "\n",
      "[[96  1]\n",
      " [25 75]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier 0.9898477157360406\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       1.00      0.98      0.99        97\n",
      "       others       0.98      1.00      0.99       100\n",
      "\n",
      "  avg / total       0.99      0.99      0.99       197\n",
      "\n",
      "[[ 95   2]\n",
      " [  0 100]]\n",
      "KNeighborsClassifier 0.5888324873096447\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       0.55      0.99      0.70        97\n",
      "       others       0.95      0.20      0.33       100\n",
      "\n",
      "  avg / total       0.75      0.59      0.51       197\n",
      "\n",
      "[[96  1]\n",
      " [80 20]]\n",
      "RandomForestClassifier 0.9695431472081218\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       0.99      0.95      0.97        97\n",
      "       others       0.95      0.99      0.97       100\n",
      "\n",
      "  avg / total       0.97      0.97      0.97       197\n",
      "\n",
      "[[92  5]\n",
      " [ 1 99]]\n",
      "LogisticRegression 0.9796954314720813\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       0.99      0.97      0.98        97\n",
      "       others       0.97      0.99      0.98       100\n",
      "\n",
      "  avg / total       0.98      0.98      0.98       197\n",
      "\n",
      "[[94  3]\n",
      " [ 1 99]]\n",
      "LinearSVC 0.9847715736040609\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "sanbernardino       1.00      0.97      0.98        97\n",
      "       others       0.97      1.00      0.99       100\n",
      "\n",
      "  avg / total       0.99      0.98      0.98       197\n",
      "\n",
      "[[ 94   3]\n",
      " [  0 100]]\n",
      "SGDClassifier 0.9849246231155779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       1.00      0.97      0.98        99\n",
      "     others       0.97      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       199\n",
      "\n",
      "[[ 96   3]\n",
      " [  0 100]]\n",
      "MultinomialNB 0.8743718592964824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       0.80      1.00      0.89        99\n",
      "     others       1.00      0.75      0.86       100\n",
      "\n",
      "avg / total       0.90      0.87      0.87       199\n",
      "\n",
      "[[99  0]\n",
      " [25 75]]\n",
      "PassiveAggressiveClassifier 0.9849246231155779\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       0.98      0.99      0.98        99\n",
      "     others       0.99      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       199\n",
      "\n",
      "[[98  1]\n",
      " [ 2 98]]\n",
      "KNeighborsClassifier 0.5778894472361809\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       0.54      1.00      0.70        99\n",
      "     others       1.00      0.16      0.28       100\n",
      "\n",
      "avg / total       0.77      0.58      0.49       199\n",
      "\n",
      "[[99  0]\n",
      " [84 16]]\n",
      "RandomForestClassifier 0.9346733668341709\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       0.96      0.91      0.93        99\n",
      "     others       0.91      0.96      0.94       100\n",
      "\n",
      "avg / total       0.94      0.93      0.93       199\n",
      "\n",
      "[[90  9]\n",
      " [ 4 96]]\n",
      "LogisticRegression 0.9597989949748744\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       0.96      0.96      0.96        99\n",
      "     others       0.96      0.96      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       199\n",
      "\n",
      "[[95  4]\n",
      " [ 4 96]]\n",
      "LinearSVC 0.9698492462311558\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    orlando       0.97      0.97      0.97        99\n",
      "     others       0.97      0.97      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       199\n",
      "\n",
      "[[96  3]\n",
      " [ 3 97]]\n",
      "SGDClassifier 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       0.97      1.00      0.99       100\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  3  97]]\n",
      "MultinomialNB 0.835\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       0.75      1.00      0.86       100\n",
      "     others       1.00      0.67      0.80       100\n",
      "\n",
      "avg / total       0.88      0.83      0.83       200\n",
      "\n",
      "[[100   0]\n",
      " [ 33  67]]\n",
      "PassiveAggressiveClassifier 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       0.96      1.00      0.98       100\n",
      "     others       1.00      0.96      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  4  96]]\n",
      "KNeighborsClassifier 0.59\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       0.55      1.00      0.71       100\n",
      "     others       1.00      0.18      0.31       100\n",
      "\n",
      "avg / total       0.77      0.59      0.51       200\n",
      "\n",
      "[[100   0]\n",
      " [ 82  18]]\n",
      "RandomForestClassifier 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       1.00      0.97      0.98       100\n",
      "     others       0.97      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 100]]\n",
      "LogisticRegression 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       0.96      1.00      0.98       100\n",
      "     others       1.00      0.96      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  4  96]]\n",
      "LinearSVC 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   lasvegas       0.97      1.00      0.99       100\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[100   0]\n",
      " [  3  97]]\n",
      "SGDClassifier 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       1.00      1.00      1.00       100\n",
      "      others       1.00      1.00      1.00       100\n",
      "\n",
      " avg / total       1.00      1.00      1.00       200\n",
      "\n",
      "[[100   0]\n",
      " [  0 100]]\n",
      "MultinomialNB 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       0.89      1.00      0.94       100\n",
      "      others       1.00      0.88      0.94       100\n",
      "\n",
      " avg / total       0.95      0.94      0.94       200\n",
      "\n",
      "[[100   0]\n",
      " [ 12  88]]\n",
      "PassiveAggressiveClassifier 0.995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       0.99      1.00      1.00       100\n",
      "      others       1.00      0.99      0.99       100\n",
      "\n",
      " avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[100   0]\n",
      " [  1  99]]\n",
      "KNeighborsClassifier 0.505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       0.50      1.00      0.67       100\n",
      "      others       1.00      0.01      0.02       100\n",
      "\n",
      " avg / total       0.75      0.51      0.34       200\n",
      "\n",
      "[[100   0]\n",
      " [ 99   1]]\n",
      "RandomForestClassifier 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       1.00      0.94      0.97       100\n",
      "      others       0.94      1.00      0.97       100\n",
      "\n",
      " avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[ 94   6]\n",
      " [  0 100]]\n",
      "LogisticRegression 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       0.99      0.97      0.98       100\n",
      "      others       0.97      0.99      0.98       100\n",
      "\n",
      " avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[97  3]\n",
      " [ 1 99]]\n",
      "LinearSVC 0.995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "charliehebdo       0.99      1.00      1.00       100\n",
      "      others       1.00      0.99      0.99       100\n",
      "\n",
      " avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[100   0]\n",
      " [  1  99]]\n",
      "SGDClassifier 0.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       0.99      0.99      0.99       100\n",
      "     others       0.99      0.99      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "[[99  1]\n",
      " [ 1 99]]\n",
      "MultinomialNB 0.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       0.88      1.00      0.93       100\n",
      "     others       1.00      0.86      0.92       100\n",
      "\n",
      "avg / total       0.94      0.93      0.93       200\n",
      "\n",
      "[[100   0]\n",
      " [ 14  86]]\n",
      "PassiveAggressiveClassifier 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       1.00      0.97      0.98       100\n",
      "     others       0.97      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 100]]\n",
      "KNeighborsClassifier 0.575\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       0.54      0.98      0.70       100\n",
      "     others       0.89      0.17      0.29       100\n",
      "\n",
      "avg / total       0.72      0.57      0.49       200\n",
      "\n",
      "[[98  2]\n",
      " [83 17]]\n",
      "RandomForestClassifier 0.96\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       1.00      0.92      0.96       100\n",
      "     others       0.93      1.00      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       200\n",
      "\n",
      "[[ 92   8]\n",
      " [  0 100]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       0.99      0.95      0.97       100\n",
      "     others       0.95      0.99      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[95  5]\n",
      " [ 1 99]]\n",
      "LinearSVC 0.985\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    japan18       1.00      0.97      0.98       100\n",
      "     others       0.97      1.00      0.99       100\n",
      "\n",
      "avg / total       0.99      0.98      0.98       200\n",
      "\n",
      "[[ 97   3]\n",
      " [  0 100]]\n",
      "SGDClassifier 0.995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       1.00      0.99      0.99       100\n",
      "     others       0.99      1.00      1.00       100\n",
      "\n",
      "avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[ 99   1]\n",
      " [  0 100]]\n",
      "MultinomialNB 0.925\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       0.87      1.00      0.93       100\n",
      "     others       1.00      0.85      0.92       100\n",
      "\n",
      "avg / total       0.93      0.93      0.92       200\n",
      "\n",
      "[[100   0]\n",
      " [ 15  85]]\n",
      "PassiveAggressiveClassifier 0.995\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       1.00      0.99      0.99       100\n",
      "     others       0.99      1.00      1.00       100\n",
      "\n",
      "avg / total       1.00      0.99      0.99       200\n",
      "\n",
      "[[ 99   1]\n",
      " [  0 100]]\n",
      "KNeighborsClassifier 0.645\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       0.59      0.98      0.73       100\n",
      "     others       0.94      0.31      0.47       100\n",
      "\n",
      "avg / total       0.76      0.65      0.60       200\n",
      "\n",
      "[[98  2]\n",
      " [69 31]]\n",
      "RandomForestClassifier 0.97\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       0.98      0.96      0.97       100\n",
      "     others       0.96      0.98      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "[[96  4]\n",
      " [ 2 98]]\n",
      "LogisticRegression 0.98\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       0.98      0.98      0.98       100\n",
      "     others       0.98      0.98      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       200\n",
      "\n",
      "[[98  2]\n",
      " [ 2 98]]\n",
      "LinearSVC 0.99\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     kerala       0.99      0.99      0.99       100\n",
      "     others       0.99      0.99      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       200\n",
      "\n",
      "[[99  1]\n",
      " [ 1 99]]\n",
      "SGDClassifier 0.9833333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.96      1.00      0.98        80\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       180\n",
      "\n",
      "[[80  0]\n",
      " [ 3 97]]\n",
      "MultinomialNB 0.9666666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.93      1.00      0.96        80\n",
      "     others       1.00      0.94      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       180\n",
      "\n",
      "[[80  0]\n",
      " [ 6 94]]\n",
      "PassiveAggressiveClassifier 0.9833333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.96      1.00      0.98        80\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       180\n",
      "\n",
      "[[80  0]\n",
      " [ 3 97]]\n",
      "KNeighborsClassifier 0.9111111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.84      0.99      0.91        80\n",
      "     others       0.99      0.85      0.91       100\n",
      "\n",
      "avg / total       0.92      0.91      0.91       180\n",
      "\n",
      "[[79  1]\n",
      " [15 85]]\n",
      "RandomForestClassifier 0.9611111111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.95      0.96      0.96        80\n",
      "     others       0.97      0.96      0.96       100\n",
      "\n",
      "avg / total       0.96      0.96      0.96       180\n",
      "\n",
      "[[77  3]\n",
      " [ 4 96]]\n",
      "LogisticRegression 0.9722222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.95      0.99      0.97        80\n",
      "     others       0.99      0.96      0.97       100\n",
      "\n",
      "avg / total       0.97      0.97      0.97       180\n",
      "\n",
      "[[79  1]\n",
      " [ 4 96]]\n",
      "LinearSVC 0.9833333333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    gujarat       0.96      1.00      0.98        80\n",
      "     others       1.00      0.97      0.98       100\n",
      "\n",
      "avg / total       0.98      0.98      0.98       180\n",
      "\n",
      "[[80  0]\n",
      " [ 3 97]]\n"
     ]
    }
   ],
   "source": [
    "CHUNK = 100\n",
    "\n",
    "for label in labels:\n",
    "    data = []\n",
    "    pool = [[label], [x for x in labels if x != label]]\n",
    "    for x in pool:\n",
    "        data.append(archive.mergeEventArticles(x, CHUNK))\n",
    "    \n",
    "    train_data, test_data = [], []\n",
    "    train_label, test_label = numpy.array([]), numpy.array([])\n",
    "\n",
    "    TRAIN_SIZE = 50\n",
    "    l = 0\n",
    "    for cat in data:\n",
    "        for x in cat[:TRAIN_SIZE]:\n",
    "            train_data.append(x['text'])\n",
    "            train_label = numpy.append(train_label, l)\n",
    "        for x in cat[TRAIN_SIZE:]:\n",
    "            test_data.append(x['text'])\n",
    "            test_label = numpy.append(test_label, l)\n",
    "        l += 1\n",
    "        \n",
    "    test_data.extend(train_data)\n",
    "    test_label = numpy.append(test_label, train_label)\n",
    "                     \n",
    "    for c in classifiers:\n",
    "        clf = Pipeline([('vect', CountVectorizer(analyzer=stemmed_words,\n",
    "                                                 stop_words='english')),\n",
    "                        ('tfidf', TfidfTransformer()),\n",
    "                        ('clf', c),\n",
    "        ])\n",
    "        clf.fit(train_data, train_label)\n",
    "        pred_label = clf.predict(test_data)\n",
    "        print(type(c).__name__, accuracy_score(test_label, pred_label))\n",
    "        print(classification_report(test_label, pred_label, target_names= [label , 'others']))\n",
    "        print(confusion_matrix(test_label, pred_label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
